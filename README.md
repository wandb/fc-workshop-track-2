# ğŸ¤– Agentic AI Systems Workshop

## ğŸ™ï¸ Operation SENTINEL GRID

NeoCatalis, a fully connected smart city, has experienced a systemic AI blackout. This workshop simulates rebuilding the city's autonomy using modern agentic principles through two comprehensive sessions.

---

## ğŸš€ **Quick Start**

### **Setup**
```bash
# Install uv package manager
pip install uv

# Create and activate virtual environment
uv venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
uv sync

# Set up environment variables
cp .env.example .env
# Add your AWS credentials to .env (openai for now)
# Add your wandb API Key to .env
```

### **Run Workshop**
```bash
# Morning session (3 hours)
python morning_session.py

# Afternoon session (3 hours) 
python afternoon_session.py
```

---

## ğŸŒ… **MORNING SESSION: Building Agentic AI Systems**

### Learning Objective
Learn to design and orchestrate agentic AI systems using modern frameworks. Cover tool use, task planning, autonomy, multi-agent collaboration, and Model Context Protocol (MCP) for dynamic external system integration.

### What You'll Build
- Multi-agent systems with specialized domain expertise
- Dynamic tool discovery and structured outputs
- Production-ready agent orchestration patterns
- Comparative evaluation: Rules vs Agents vs LLM chains

### Key Phases
1. **Environment Setup** - Service discovery and crisis scenarios
2. **LLM Chain Analysis** - Why sophisticated prompting isn't enough
3. **Service Investigation** - Grid, Emergency, Traffic (Rules â†’ Tools â†’ Agents)
4. **System Comparison** - Full rule-based vs agent-based systems
5. **Adaptability Test** - New scenario evaluation
6. **MCP Integration** - Dynamic tool discovery
7. **Results Analysis** - Performance comparison and insights

---

## ğŸŒ† **AFTERNOON SESSION: Optimization & Evaluation**

### Learning Objective
Shift from building to optimizing agentic AI applications. Implement evaluation strategies, optimize responsiveness, integrate human feedback, and prepare for production deployment.

### What You'll Build
- Comprehensive evaluation frameworks with LLM-as-a-Judge
- Performance optimization techniques
- Human feedback integration systems
- Production monitoring and scalability patterns
- Competitive optimization showcase

### Key Phases
1. **Evaluation Framework** - Multi-dimensional metrics and LLM-as-a-Judge
2. **Baseline Measurement** - Performance testing across scenarios
3. **MCP Integration** - Dynamic service discovery and tool registration
4. **Human Feedback** - Agent adaptation and behavioral modification
5. **Production Patterns** - Scalable architecture design
6. **Final Competition** - 6-dimensional scoring and leaderboard

---

## ğŸ—ï¸ **Technical Infrastructure**

### SENTINEL GRID Services
- **âš¡ Grid Management**: Power distribution, load balancing, infrastructure priorities
- **ğŸš Emergency Response**: Drone deployment, incident management, resource allocation  
- **ğŸš¦ Traffic Coordination**: Flow optimization, emergency corridors, congestion management

### Key Scenarios
- Heat Wave Crisis, Cyber Attack, Major Earthquake, Festival Emergency, Complex Multi-Domain Crisis

### Evaluation Metrics
- Incident Coverage, Response Time, Tool Failure Handling, Capability Match, Latency, Decision Quality

---

## ğŸ“ **Repository Structure**

```
/
â”œâ”€â”€ morning_session.py              # Morning workshop (building agents)
â”œâ”€â”€ afternoon_session.py            # Afternoon workshop (optimization)
â”œâ”€â”€ workshop/                       # Core infrastructure
â”‚   â”œâ”€â”€ command.py                  # Command execution system
â”‚   â”œâ”€â”€ agent_system.py             # Agent orchestration
â”‚   â”œâ”€â”€ state_management.py         # Service state handling
â”‚   â”œâ”€â”€ command_evaluator.py        # Performance evaluation
â”‚   â”œâ”€â”€ agent_converter.py          # Agent result processing
â”‚   â”œâ”€â”€ afternoon_session_utils.py  # Optimization utilities
â”‚   â”œâ”€â”€ scenarios.py                # Crisis scenarios
â”‚   â”œâ”€â”€ state_models.py             # Data models
â”‚   â”œâ”€â”€ service_management.py       # Service lifecycle
â”‚   â”œâ”€â”€ config.py                   # Configuration
â”‚   â”œâ”€â”€ day_seed_generator.py       # Scenario generation
â”‚   â””â”€â”€ services/                   # Service implementations
â”œâ”€â”€ results/                        # Workshop analytics
â””â”€â”€ .env.example                    # Environment template
```

---

## ğŸ“ **Learning Objectives**

### Technical Skills
- Design modular agentic systems using CrewAI
- Build specialized tools with structured outputs
- Implement comprehensive evaluation frameworks
- Optimize performance through various techniques
- Integrate human feedback for continuous improvement
- Utilize MCP for dynamic tool discovery

### Conceptual Understanding
- Agent vs Rule-Based Systems trade-offs
- Multi-agent coordination patterns
- Production deployment considerations
- Evaluation methodologies beyond success metrics
- Human-AI interaction and feedback loops

---

## ğŸ† **Workshop Format**

- **Morning (3 hours)**: Foundation building and agent development
- **â˜• Break (1 hour)**: Lunch and networking
- **Afternoon (3 hours)**: Optimization, evaluation, and competition
- **Interactive**: Jupyter notebook format with hands-on exercises
- **Competitive**: Final leaderboard across 6 evaluation dimensions

